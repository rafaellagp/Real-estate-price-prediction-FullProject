{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gettext import npgettext\n",
    "from pyexpat import features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble\n",
    "import pickle\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_model.csv')\n",
    "df_code = pd.read_excel('zipcode_be.xlsx')\n",
    "df = df.rename({'Unnamed: 0': 'id'}, axis=1)\n",
    "\n",
    "df['code'] = df['zip_code']\n",
    "df_code['code']=df_code['code'].astype(int)\n",
    "df['code']=df['code'].astype(int)\n",
    "df = df.merge(df_code, on='code', how='left')\n",
    "df = df.drop_duplicates(subset=\"id\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column, zscore = 3):\n",
    "    upper_limit = df[column].mean() + zscore * df[column].std()\n",
    "    lower_limit = df[column].mean() - zscore * df[column].std()\n",
    "    normal_df = df[(df[column] < upper_limit) & (df[column] > lower_limit)]\n",
    "    return normal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['building_state'] = (df['building_state']).replace({'good': 0, 'to renovate': 0, 'as new': 1, 'to be done up': 0, \n",
    "'just renovated': 0, 'to restor':0, 'to rebuild':0 , 'not mentioned': 0})\n",
    "labels = df['price']\n",
    "df = remove_outliers(df, 'price')\n",
    "df = df.drop(['id','full_address','name','province'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  df['price']\n",
    "df_features = df.drop([\"property_type\", 'price'],axis=1)\n",
    "\n",
    "def model(df, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, labels, test_size = 0.3,random_state=2)\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators=400,max_depth=6,min_samples_split=2,learning_rate=0.1,loss= 'squared_error')\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'finalized_model.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    score = clf.score(X_test,y_test)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Score :', score)\n",
    "    print('Predicted price:', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(df, labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df_features, labels, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m clf \u001b[38;5;241m=\u001b[39m ensemble\u001b[38;5;241m.\u001b[39mGradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,loss\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# save the model to disk\u001b[39;00m\n\u001b[1;32m     10\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalized_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/BeCode/challenge-api-deployment/env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:668\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    667\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 668\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[1;32m    669\u001b[0m     X,\n\u001b[1;32m    670\u001b[0m     y,\n\u001b[1;32m    671\u001b[0m     raw_predictions,\n\u001b[1;32m    672\u001b[0m     sample_weight,\n\u001b[1;32m    673\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[1;32m    674\u001b[0m     X_val,\n\u001b[1;32m    675\u001b[0m     y_val,\n\u001b[1;32m    676\u001b[0m     sample_weight_val,\n\u001b[1;32m    677\u001b[0m     begin_at_stage,\n\u001b[1;32m    678\u001b[0m     monitor,\n\u001b[1;32m    679\u001b[0m )\n\u001b[1;32m    681\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/BeCode/challenge-api-deployment/env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:745\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    738\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    739\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    740\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    741\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    742\u001b[0m     )\n\u001b[1;32m    744\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[1;32m    746\u001b[0m     i,\n\u001b[1;32m    747\u001b[0m     X,\n\u001b[1;32m    748\u001b[0m     y,\n\u001b[1;32m    749\u001b[0m     raw_predictions,\n\u001b[1;32m    750\u001b[0m     sample_weight,\n\u001b[1;32m    751\u001b[0m     sample_mask,\n\u001b[1;32m    752\u001b[0m     random_state,\n\u001b[1;32m    753\u001b[0m     X_csc,\n\u001b[1;32m    754\u001b[0m     X_csr,\n\u001b[1;32m    755\u001b[0m )\n\u001b[1;32m    757\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/BeCode/challenge-api-deployment/env/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:247\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    244\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    246\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 247\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    249\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    250\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    251\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    252\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    260\u001b[0m )\n",
      "File \u001b[0;32m~/BeCode/challenge-api-deployment/env/lib/python3.9/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1343\u001b[0m         X,\n\u001b[1;32m   1344\u001b[0m         y,\n\u001b[1;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1347\u001b[0m     )\n\u001b[1;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/BeCode/challenge-api-deployment/env/lib/python3.9/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.7680249090319977\n",
      "Predicted price: [203801.35693217]\n",
      "Real price: €215,000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, labels, test_size = 0.3,random_state=2)\n",
    "clf = ensemble.GradientBoostingRegressor(n_estimators=400,max_depth=6,min_samples_split=2,learning_rate=0.1,loss= 'squared_error')\n",
    "clf.fit(X_train,y_train)\n",
    "score = clf.score(X_test,y_test)\n",
    "exemple_data = {'area' :[110],'rooms_number' :[3],'zip_code' :[5080],'land_area':[824],'garden':[0],'garden_area':[0],'equipped_kitchen':[0],'swimming_pool':[0],'furnished':[0],'open_fire':[0],'terrace':[0],'terrace_area':[0],'facades_number':[4],'building_state':[1],'code':[5080],'lat':[5038930954],'lng':[482362925]}\n",
    "test_df = pd.DataFrame(exemple_data)\n",
    "pred = clf.predict(test_df)\n",
    "print('Score :', score)\n",
    "print('Predicted price:', pred)\n",
    "print('Real price: €215,000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickled_model = pickle.load(open('/Users/rafaellaporto/BeCode/challenge-api-deployment/model/finalized_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.model(df, labels)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mpickled_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_address\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovince\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = pickled_model.predict(df.drop(['full_address','property_type', 'name', 'province'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(df):\n",
    "    print(\"predict df:\", df)\n",
    "    pickled_model = pickle.load(open('./model/finalized_model.sav', 'rb'))\n",
    "    df_code = pd.read_excel('./model/zipcode_be.xlsx')\n",
    "    df['code'] = df['zip_code']\n",
    "    df['code']=df['code'].astype(int)\n",
    "    df = df.merge(df_code, on='code', how='left')\n",
    "    pred = pickled_model.predict(df.drop(['full_address','property_type', 'name', 'province'], axis=1))\n",
    "    print('Predicted price:', pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.8144485249819912\n",
      "Predicted price: [ 253825.44438504  449971.0670777   169687.92533861 ...  233318.35052367\n",
      " 1430922.23752818  500554.1151499 ]\n"
     ]
    }
   ],
   "source": [
    "def model(df, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, labels, test_size = 0.3,random_state=2)\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators=400,max_depth=6,min_samples_split=2,learning_rate=0.1,loss= 'squared_error')\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'finalized_model.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    score = clf.score(X_test,y_test)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Score :', score)\n",
    "    print('Predicted price:', pred)\n",
    "    \n",
    "    \n",
    "model(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ef148196fbcca35443ad4afc38fc20fc385b98e5b097a76566eece9ee14becf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
